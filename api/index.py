from fastapi import FastAPI, HTTPException, Depends, Query
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from sqlalchemy import func
from pydantic import BaseModel
from datetime import datetime, timedelta
import json
import requests
from typing import List, Optional
import os
import asyncio
import logging
from http.server import BaseHTTPRequestHandler
from urllib.parse import urlsplit
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from apscheduler.schedulers.asyncio import AsyncIOScheduler

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π
try:
    from .models import (
        get_db, User, Event, EventOption, UserPrediction,
        Transaction, TransactionType, TransactionStatus, PriceHistory
    )
except ImportError:
    from models import (
        get_db, User, Event, EventOption, UserPrediction,
        Transaction, TransactionType, TransactionStatus, PriceHistory
    )

app = FastAPI(title="EventPredict API")

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
FRONTEND_DIR = os.path.join(BASE_DIR, "frontend")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# CORS –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Vercel routes keep the "/api" prefix; strip it so FastAPI routes match.
@app.middleware("http")
async def strip_api_prefix(request, call_next):
    path = request.scope.get("path", "")
    if path == "/api":
        request.scope["path"] = "/"
    elif path.startswith("/api/"):
        request.scope["path"] = path[4:] or "/"
    return await call_next(request)

# ==================== POLYMARKET API INTEGRATION ====================

POLYMARKET_API_URL = "https://gamma-api.polymarket.com"
# –ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: 2 —á–∞—Å–∞ (7200 —Å–µ–∫—É–Ω–¥) –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –∫—Ä–µ–¥–∏—Ç–æ–≤ Railway
POLYMARKET_SYNC_INTERVAL_SECONDS = int(os.getenv("POLYMARKET_SYNC_INTERVAL", "7200"))
last_polymarket_sync = datetime.min
sync_stats = {"total_synced": 0, "last_sync": None, "last_error": None}
POLYMARKET_VERBOSE_LOGS = os.getenv("POLYMARKET_VERBOSE_LOGS", "0") == "1"

# –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ: –∏—Å–ø–æ–ª—å–∑—É–µ–º candles API –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
POLYMARKET_CANDLES_URL = "https://gamma-api.polymarket.com/candles"

# –õ–∏–º–∏—Ç API –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Ü–µ–Ω (–¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç rate limit)
PRICE_HISTORY_SYNC_LIMIT = 10  # –ú–∞–∫—Å–∏–º—É–º 10 —Å–æ–±—ã—Ç–∏–π –∑–∞ —Ä–∞–∑

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
scheduler = AsyncIOScheduler()

# Admin Telegram ID
ADMIN_TELEGRAM_ID = int(os.getenv("ADMIN_TELEGRAM_ID", "1972885597"))

# CORS proxy –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π Polymarket
POLYMARKET_IMAGE_PROXY = os.getenv("POLYMARKET_IMAGE_PROXY", "https://gamma-api.polymarket.com")

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
CATEGORY_KEYWORDS = {
    'politics': ['trump', 'biden', 'election', 'president', 'congress', 'senate', 'vote', 'democrat', 'republican', 'political', 'government', 'minister', 'parliament', 'putin', 'zelensky', 'ukraine', 'russia', 'china', 'nato', 'white house', 'kremlin', 'prime minister', 'governor', 'mayor', 'policy', 'legislation', 'bill', 'veto', 'impeachment', 'sanction', 'tariff', 'embassy', 'ambassador', 'summit', 'treaty', 'alliance', 'coalition', 'party', 'campaign', 'debate', 'poll', 'ballot', 'referendum'],
    'sports': ['nba', 'nfl', 'mlb', 'soccer', 'football', 'basketball', 'baseball', 'tennis', 'golf', 'ufc', 'boxing', 'f1', 'formula', 'championship', 'world cup', 'super bowl', 'olympics', 'game', 'match', 'team', 'player', 'league', 'tournament', 'finals', 'playoffs', 'coach', 'athlete', 'sport', 'win', 'loss', 'score', 'goal', 'touchdown', 'home run'],
    'crypto': ['bitcoin', 'btc', 'ethereum', 'eth', 'crypto', 'blockchain', 'defi', 'nft', 'token', 'coin', 'binance', 'coinbase', 'solana', 'dogecoin', 'altcoin', 'mining', 'web3', 'metamask', 'wallet', 'exchange', 'trading', 'hodl', 'bull', 'bear', 'market cap', 'altseason', 'layer 2', 'staking', 'yield', 'farm'],
    'pop_culture': ['movie', 'film', 'oscar', 'grammy', 'emmy', 'celebrity', 'music', 'album', 'artist', 'actor', 'actress', 'tv show', 'netflix', 'disney', 'marvel', 'star wars', 'taylor swift', 'beyonce', 'kanye', 'pop', 'rock', 'hip hop', 'rap', 'country', 'jazz', 'concert', 'tour', 'award', 'red carpet', 'premiere', 'streaming', 'youtube', 'tiktok', 'instagram', 'influencer', 'viral', 'trending', 'meme'],
    'business': ['stock', 'market', 'company', 'ceo', 'ipo', 'merger', 'earnings', 'revenue', 'tesla', 'apple', 'google', 'amazon', 'microsoft', 'nvidia', 'ai', 'layoff', 'startup', 'fed', 'interest rate', 'inflation', 'economy', 'gdp', 'recession', 'bull market', 'bear market', 'dividend', 'bond', 'etf', 'mutual fund', 'hedge fund', 'private equity', 'venture capital', 'acquisition', 'spinoff', 'bankruptcy', 'restructuring', 'layoffs', 'hiring', 'job', 'career', 'salary', 'bonus'],
    'science': ['nasa', 'spacex', 'rocket', 'mars', 'moon', 'climate', 'vaccine', 'fda', 'research', 'discovery', 'scientist', 'study', 'experiment', 'technology', 'ai model', 'gpt', 'openai', 'physics', 'chemistry', 'biology', 'medicine', 'health', 'disease', 'treatment', 'drug', 'clinical trial', 'gene', 'dna', 'crispr', 'telescope', 'satellite', 'asteroid', 'comet', 'galaxy', 'universe', 'quantum', 'particle', 'atom', 'energy', 'renewable', 'solar', 'wind', 'fusion', 'fission']
}

def detect_category(title: str, description: str = '') -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å–æ–±—ã—Ç–∏—è –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É –∏ –æ–ø–∏—Å–∞–Ω–∏—é"""
    text = (title + ' ' + (description or '')).lower()

    category_scores = {}
    for category, keywords in CATEGORY_KEYWORDS.items():
        score = sum(1 for keyword in keywords if keyword in text)
        if score > 0:
            category_scores[category] = score

    if category_scores:
        return max(category_scores, key=category_scores.get)
    return 'other'

def fetch_polymarket_price_history(condition_id: str, outcome: str, resolution: str = 'hour', limit: int = 168):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –æ —Ü–µ–Ω–∞—Ö –∏–∑ Polymarket candles API

    Args:
        condition_id: ID —É—Å–ª–æ–≤–∏—è (—Ä—ã–Ω–∫–∞) –∏–∑ Polymarket
        outcome: –ù–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Yes", "No")
        resolution: –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ ('minute', 'hour', 'day', 'week')
        limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö (–º–∞–∫—Å–∏–º—É–º 168 –¥–ª—è —á–∞—Å–æ–≤)

    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (timestamp, price, volume)
    """
    try:
        # Polymarket candles API endpoint
        url = f"{POLYMARKET_CANDLES_URL}"

        params = {
            "market": condition_id,
            "outcome": outcome,
            "resolution": resolution,
            "limit": limit
        }

        headers = {
            "Accept": "application/json",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Accept-Language": "en-US,en;q=0.9",
        }

        response = requests.get(url, params=params, headers=headers, timeout=10)

        if response.status_code != 200:
            if POLYMARKET_VERBOSE_LOGS:
                print(f"   Price history API error: {response.status_code}")
            return []

        data = response.json()

        # Polymarket –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ —Å–≤–µ—á–µ–π: [timestamp, open, high, low, close, volume]
        if not isinstance(data, list) or len(data) == 0:
            if POLYMARKET_VERBOSE_LOGS:
                print(f"   No price history data for {condition_id} / {outcome}")
            return []

        history = []
        for candle in data:
            if len(candle) >= 6:
                timestamp = datetime.utcfromtimestamp(candle[0] / 1000)  # ms ‚Üí seconds
                close_price = candle[4] / 100  # Polymarket –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 0-100, –Ω–∞–º –Ω—É–∂–Ω–æ 0-1
                volume = candle[5]
                history.append((timestamp, close_price, volume))

        if POLYMARKET_VERBOSE_LOGS:
            print(f"   Fetched {len(history)} price history points for {condition_id} / {outcome}")

        return history

    except requests.exceptions.Timeout:
        if POLYMARKET_VERBOSE_LOGS:
            print(f"   Timeout fetching price history for {condition_id} / {outcome}")
        return []
    except requests.exceptions.RequestException as e:
        if POLYMARKET_VERBOSE_LOGS:
            print(f"   Request error fetching price history: {e}")
        return []
    except Exception as e:
        if POLYMARKET_VERBOSE_LOGS:
            print(f"   Error fetching price history: {e}")
        return []

def fetch_polymarket_events(limit: int = 50, category: str = None):
    """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –∏–∑ Polymarket API"""
    try:
        print(f"=== fetch_polymarket_events START ===")
        print(f"Limit: {limit}, Category: {category}")
        
        # –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ /markets —á–∞—â–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è (–≤–∫–ª—é—á–∞—è –∏—Å—Ö–æ–¥—ã)
        primary_url = "https://gamma-api.polymarket.com/markets"
        secondary_url = "https://gamma-api.polymarket.com/events"

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ (–≤–∞–∂–Ω–æ: –ù–ï –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º brotli 'br', —Ç.–∫. requests –±–µ–∑ –¥–æ–ø. –ø–∞–∫–µ—Ç–æ–≤ –º–æ–∂–µ—Ç –Ω–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å)
        headers = {
            "Accept": "application/json",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Accept-Language": "en-US,en;q=0.9",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
        }

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–¥–ª—è /markets –∏ /events)
        params = {
            "order": "id",
            "ascending": "false",
            "closed": "false",
            "active": "true",
            "limit": limit,
        }

        def _do_get(url: str):
            if POLYMARKET_VERBOSE_LOGS:
                print(f"Fetching from Polymarket: {url}")
                print(f"Params: {params}")
            resp = requests.get(url, params=params, headers=headers, timeout=30)
            print(f"Response: status={resp.status_code}, content-length={len(resp.content)}")
            return resp

        response = _do_get(primary_url)
        
        if POLYMARKET_VERBOSE_LOGS:
            print(f"Response status: {response.status_code}")
            print(f"Content-Type: {response.headers.get('content-type', 'unknown')}")
        
        if response.status_code != 200:
            print(f"HTTP error: {response.status_code}")
            print(f"Response: {response.text[:500]}")
            # fallback to /events
            response = _do_get(secondary_url)

        if response.status_code != 200:
            print(f"HTTP error: {response.status_code}")
            print(f"Response: {response.text[:500]}")
            return []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Content-Type
        content_type = response.headers.get('content-type', '').lower()
        if 'application/json' not in content_type:
            print(f"Wrong content-type: {content_type}")
            print(f"Response preview: {response.text[:200]}")
            return []

        if POLYMARKET_VERBOSE_LOGS:
            print(f"Response preview (first 1000 chars): {response.text[:1000]}")
        
        try:
            events_data = response.json()
        except ValueError as e:
            print(f"JSON parsing error: {e}")
            print(f"Response preview: {response.text[:200]}")
            return []

        # API –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫, –ª–∏–±–æ –æ–±—ä–µ–∫—Ç –≤–∏–¥–∞ {"events": [...]}/{"markets": [...]}
        events_list = None
        if isinstance(events_data, list):
            events_list = events_data
        elif isinstance(events_data, dict):
            if isinstance(events_data.get("events"), list):
                events_list = events_data.get("events")
            elif isinstance(events_data.get("markets"), list):
                events_list = events_data.get("markets")
            elif isinstance(events_data.get("data"), list):
                events_list = events_data.get("data")
            elif isinstance(events_data.get("results"), list):
                events_list = events_data.get("results")

        if events_list is None:
            print(f"Unexpected Polymarket response shape: {type(events_data)}")
            if POLYMARKET_VERBOSE_LOGS:
                print(f"Response preview: {str(events_data)[:1000]}")
            return []

        print(f"Received {len(events_list)} events from Polymarket")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä—ã–Ω–∫–∏/—Å–æ–±—ã—Ç–∏—è
        events = []
        for idx, event in enumerate(events_list):
            if POLYMARKET_VERBOSE_LOGS:
                print(f"Processing event #{idx}: {str(event)[:200]}...")
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞
            question = event.get('question') or event.get('title') or event.get('description')
            if not question:
                print("   No question/title/description found")
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥—ã/–æ–ø—Ü–∏–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
            tokens = event.get("tokens")
            outcomes = event.get("outcomes")
            outcome_prices = event.get("outcomePrices") or event.get("outcome_prices")

            options = []
            volumes = []

            # –ü–∞—Ä—Å–∏–º outcomes –µ—Å–ª–∏ —ç—Ç–æ JSON —Å—Ç—Ä–æ–∫–∞
            if isinstance(outcomes, str):
                try:
                    outcomes = json.loads(outcomes)
                except Exception:
                    pass

            # 1) tokens (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç)
            if isinstance(tokens, list) and tokens:
                for token in tokens:
                    outcome = token.get("outcome", "")
                    if not outcome:
                        continue
                    price = float(token.get("price", 0.5) or 0.5)
                    options.append(outcome)
                    volumes.append(price * 1000)

            # 2) outcomes + outcomePrices (—á–∞—Å—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç /markets)
            elif isinstance(outcomes, list) and outcomes:
                options = [str(o) for o in outcomes]
                if isinstance(outcome_prices, list) and len(outcome_prices) == len(options):
                    for p in outcome_prices:
                        try:
                            volumes.append(float(p) * 1000)
                        except Exception:
                            volumes.append(500.0)
                else:
                    volumes = [500.0 for _ in options]

            if not options:
                # –ù–µ—á–µ–≥–æ —Å–∏–Ω–∫–∞—Ç—å
                continue
            
            if POLYMARKET_VERBOSE_LOGS:
                print(f"   Found question: {question}")
                print(f"   Found {len(tokens)} tokens")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–±—ã—Ç–∏—è
            title = question
            description = event.get('description', '')
            detected_category = detect_category(title, description)

            if category and category != 'all' and detected_category != category:
                print(f"   Skipping - category {detected_category} != {category}")
                continue

            if POLYMARKET_VERBOSE_LOGS:
                print(f"   Options: {options}")
            
            # –ü–æ–ª—É—á–∞–µ–º ID —Å–æ–±—ã—Ç–∏—è
            event_id = event.get('conditionId') or event.get('id') or str(idx)
            
            event_data = {
                'polymarket_id': event_id,
                'title': title,
                'description': description,
                'category': detected_category,
                'image_url': event.get('image', ''),
                'end_time': event.get('endDate', '') or event.get('end_date', ''),
                'options': options,
                'volumes': volumes
            }
            
            events.append(event_data)
            if POLYMARKET_VERBOSE_LOGS:
                print(f"   Created event data: {title}")
        
        print(f"Processed {len(events)} valid events")
        print(f"=== fetch_polymarket_events END ===")
        return events

    except requests.exceptions.RequestException as e:
        print(f"Network error: {e}")
        print(f"=== fetch_polymarket_events ERROR ===")
        return []
    except Exception as e:
        print(f"Error fetching Polymarket events: {e}")
        import traceback
        traceback.print_exc()
        print(f"=== fetch_polymarket_events ERROR ===")
        return []

def parse_polymarket_end_time(end_time: str) -> datetime:
    if not end_time:
        return datetime.utcnow() + timedelta(days=7)
    try:
        # Parse with timezone and convert to naive UTC
        dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
        return dt.replace(tzinfo=None)  # Convert to naive UTC
    except Exception as e:
        print(f"Error parsing end time: {e}")
        return datetime.utcnow() + timedelta(days=7)

def update_event_total_pool(db: Session, event: Event) -> None:
    options = db.query(EventOption).filter(EventOption.event_id == event.id).all()
    event.total_pool = sum(
        (opt.total_stake or 0.0) + (opt.market_stake or 0.0)
        for opt in options
    )

def upsert_polymarket_event(db: Session, pm_event: dict) -> bool:
    print(f"Upserting event: {pm_event.get('title', 'No title')}")
    
    end_time = parse_polymarket_end_time(pm_event.get('end_time'))
    is_active = end_time > datetime.utcnow()
    options = pm_event.get('options', [])
    volumes = pm_event.get('volumes', [])
    
    print(f"   - Parsed end time: {end_time}")
    print(f"   - Is active: {is_active}")
    print(f"   - Options count: {len(options)}")
    print(f"   - Volumes: {volumes}")

    polymarket_id = pm_event.get('polymarket_id', '')
    if not polymarket_id:
        print("   No polymarket_id - skipping")
        return False

    existing = db.query(Event).filter(
        Event.polymarket_id == polymarket_id
    ).first()

    if existing:
        print(f"   Updating existing event (ID: {existing.id})")
        existing.title = pm_event['title'][:500]
        existing.description = pm_event['description'][:1000] if pm_event['description'] else None
        existing.category = pm_event.get('category', existing.category)
        existing.image_url = pm_event.get('image_url', '')
        existing.end_time = end_time
        existing.is_active = is_active
        existing.options = json.dumps(options)

        existing_options = {
            opt.option_index: opt
            for opt in db.query(EventOption).filter(EventOption.event_id == existing.id).all()
        }

        for idx, (option_text, volume) in enumerate(zip(options, volumes)):
            option = existing_options.get(idx)
            if option:
                option.option_text = option_text
                option.market_stake = volume
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω
                price = volume / (sum(volumes) or 1)
                option.current_price = price

                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Polymarket
                # –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ü–µ–Ω –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
                # —á—Ç–æ–±—ã –Ω–µ –∑–∞–º–µ–¥–ª—è—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é —Å–æ–±—ã—Ç–∏–π
                condition_id = pm_event.get('polymarket_id', '')
                # –ò—Å—Ç–æ—Ä–∏—è –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ sync_polymarket_price_history()

                print(f"   Updated option {idx}: {option_text}, price: {price:.2%}")
            else:
                new_option = EventOption(
                    event_id=existing.id,
                    option_index=idx,
                    option_text=option_text,
                    total_stake=0.0,
                    market_stake=volume,
                    current_price=volume / (sum(volumes) or 1)
                )
                db.add(new_option)
                print(f"   Added option {idx}: {option_text}")

        for idx, option in existing_options.items():
            if idx >= len(options):
                db.delete(option)
                print(f"   Deleted option {idx}")

        update_event_total_pool(db, existing)
        print("   Event updated successfully")
        return False

    print("   Creating new event")
    new_event = Event(
        polymarket_id=polymarket_id,
        title=pm_event['title'][:500],
        description=pm_event['description'][:1000] if pm_event['description'] else None,
        category=pm_event.get('category', 'other'),
        image_url=pm_event.get('image_url', ''),
        options=json.dumps(options),
        end_time=end_time,
        is_active=is_active,
        is_moderated=True,
        total_pool=sum(volumes)
    )
    db.add(new_event)
    db.flush()
    print(f"   Created event with ID: {new_event.id}")

    for idx, (option_text, volume) in enumerate(zip(options, volumes)):
        new_option = EventOption(
            event_id=new_event.id,
            option_index=idx,
            option_text=option_text,
            total_stake=0.0,
            market_stake=volume,
            current_price=volume / (sum(volumes) or 1)
        )
        db.add(new_option)

        # –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ü–µ–Ω –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
        # —á—Ç–æ–±—ã –Ω–µ –∑–∞–º–µ–¥–ª—è—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é —Å–æ–±—ã—Ç–∏–π
        # –ò—Å—Ç–æ—Ä–∏—è –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ sync_polymarket_price_history()

        print(f"   Added option {idx}: {option_text}")

    print(f"   New event created successfully")
    return True


def sync_polymarket_price_history(db: Session = None, limit: int = PRICE_HISTORY_SYNC_LIMIT):
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–±—ã—Ç–∏–π
    
    Args:
        db: –°–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞ –æ–¥–∏–Ω —Ä–∞–∑
    """
    try:
        if db is None:
            db = next(get_db())
        
        logger.info(f"üìà Starting Polymarket price history sync (limit: {limit} events)...")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        events = db.query(Event).filter(
            Event.is_active == True,
            Event.end_time > datetime.utcnow()
        ).order_by(Event.id.desc()).limit(limit).all()
        
        total_history_points = 0
        
        for event in events:
            try:
                options = db.query(EventOption).filter(
                    EventOption.event_id == event.id
                ).all()
                
                for option in options:
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω
                        history_data = fetch_polymarket_price_history(
                            event.polymarket_id,
                            option.option_text,
                            'hour',
                            168
                        )
                        
                        if history_data:
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
                            for hist_timestamp, hist_price, hist_volume in history_data:
                                existing_hist = db.query(PriceHistory).filter(
                                    PriceHistory.event_id == event.id,
                                    PriceHistory.option_index == option.option_index,
                                    PriceHistory.timestamp == hist_timestamp
                                ).first()
                                if not existing_hist:
                                    new_history = PriceHistory(
                                        event_id=event.id,
                                        option_index=option.option_index,
                                        price=hist_price,
                                        volume=hist_volume,
                                        timestamp=hist_timestamp
                                    )
                                    db.add(new_history)
                                    total_history_points += 1
                            
                            logger.info(f"  Added {len(history_data)} history points for {event.title[:30]} / {option.option_text}")
                        
                        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç rate limit
                        import time
                        time.sleep(0.2)
                        
                    except Exception as e:
                        logger.warning(f"  Error syncing history for option {option.option_index}: {e}")
                        continue
                
            except Exception as e:
                logger.warning(f"  Error syncing history for event {event.id}: {e}")
                continue
        
        db.commit()
        logger.info(f"‚úÖ Price history sync completed: {total_history_points} new points")
        
    except Exception as e:
        logger.error(f"‚ùå Price history sync error: {e}")
        if db:
            db.rollback()


def sync_polymarket_events(db: Session = None):
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Å–æ–±—ã—Ç–∏—è –∏–∑ Polymarket –≤ –ë–î"""
    try:
        logger.info("üîÑ Starting Polymarket sync...")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é –ë–î –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞
        if db is None:
            db = next(get_db())
        
        polymarket_events = fetch_polymarket_events(limit=300)
        synced_count = 0
        added_count = 0
        updated_count = 0

        for pm_event in polymarket_events:
            created = upsert_polymarket_event(db, pm_event)
            if created:
                added_count += 1
            else:
                updated_count += 1
            synced_count += 1
            logger.info(f"  {'‚úÖ Added' if created else 'üîÑ Updated'}: {pm_event['title'][:50]}...")

        db.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        sync_stats["total_synced"] = synced_count
        sync_stats["last_sync"] = datetime.utcnow()
        sync_stats["last_error"] = None
        
        logger.info(f"‚úÖ Sync completed: {synced_count} events ({added_count} new, {updated_count} updated)")
        return synced_count
    except Exception as e:
        logger.error(f"‚ùå Error syncing events: {e}")
        sync_stats["last_error"] = str(e)
        return 0


def scheduled_sync():
    """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ - —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π"""
    try:
        sync_polymarket_events()
    except Exception as e:
        logger.error(f"Scheduled sync error: {e}")

def scheduled_price_history_sync():
    """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ - —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Ü–µ–Ω"""
    try:
        db = next(get_db())
        sync_polymarket_price_history(db, limit=PRICE_HISTORY_SYNC_LIMIT)
    except Exception as e:
        logger.error(f"Scheduled price history sync error: {e}")

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    logger.info("üöÄ Starting EventPredict API...")

    # –û—Ç–∫–ª—é—á–∞–µ–º scheduler –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
    if not os.getenv("DISABLE_SCHEDULER"):
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
        scheduler.add_job(
            scheduled_sync,
            'interval',
            seconds=POLYMARKET_SYNC_INTERVAL_SECONDS,
            id='polymarket_sync',
            replace_existing=True
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Ü–µ–Ω (–∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤)
        scheduler.add_job(
            scheduled_price_history_sync,
            'interval',
            seconds=21600,  # 6 —á–∞—Å–æ–≤
            id='price_history_sync',
            replace_existing=True
        )
        
        scheduler.start()
        logger.info(f"‚è∞ Scheduler started (events: {POLYMARKET_SYNC_INTERVAL_SECONDS}s, history: 21600s)")

        # –ü–µ—Ä–≤–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–≤ —Ñ–æ–Ω–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –∑–∞–ø—É—Å–∫)
        try:
            db = next(get_db())
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—Ç
            import threading
            sync_thread = threading.Thread(target=sync_polymarket_events, args=(db,))
            sync_thread.start()
            logger.info("üìä Initial event sync started in background...")
        except Exception as e:
            logger.error(f"Initial sync error: {e}")
    else:
        logger.info("üß™ Test mode: scheduler disabled")


@app.on_event("shutdown")
async def shutdown_event():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã"""
    logger.info("üõë Shutting down EventPredict API...")
    if not os.getenv("DISABLE_SCHEDULER"):
        scheduler.shutdown(wait=False)

# ==================== PYDANTIC MODELS ====================

class PredictionRequest(BaseModel):
    telegram_id: int
    event_id: int
    option_index: int
    points: float

class CreateEventRequest(BaseModel):
    telegram_id: int
    title: str
    description: str
    category: str
    image_url: str
    end_time: str
    options: list[str]

class AdminStats(BaseModel):
    total_users: int
    total_events: int
    pending_events: int
    total_volume: float
    total_transactions: int

class UserResponse(BaseModel):
    telegram_id: int
    username: Optional[str]
    points: float
    stats: dict


# ==================== API ENDPOINTS ====================
@app.get("/", include_in_schema=False)
async def root():
    index_path = os.path.join(FRONTEND_DIR, "index.html")
    if os.path.exists(index_path):
        return FileResponse(index_path)
    return {"status": "ok", "message": "EventPredict API"}

@app.get("/categories")
async def get_categories():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
    return {
        "categories": [
            {"id": "all", "name": "All", "icon": "üî•", "name_ru": "–í—Å–µ"},
            {"id": "politics", "name": "Politics", "icon": "üèõÔ∏è", "name_ru": "–ü–æ–ª–∏—Ç–∏–∫–∞"},
            {"id": "sports", "name": "Sports", "icon": "‚öΩ", "name_ru": "–°–ø–æ—Ä—Ç"},
            {"id": "crypto", "name": "Crypto", "icon": "‚Çø", "name_ru": "–ö—Ä–∏–ø—Ç–æ"},
            {"id": "pop_culture", "name": "Pop Culture", "icon": "üé¨", "name_ru": "–ü–æ–ø-–∫—É–ª—å—Ç—É—Ä–∞"},
            {"id": "business", "name": "Business", "icon": "üìà", "name_ru": "–ë–∏–∑–Ω–µ—Å"},
            {"id": "science", "name": "Science", "icon": "üî¨", "name_ru": "–ù–∞—É–∫–∞"},
            {"id": "other", "name": "Other", "icon": "üìå", "name_ru": "–î—Ä—É–≥–æ–µ"}
        ]
    }

@app.get("/events")
async def get_events(category: str = None, db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–±—ã—Ç–∏—è —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    try:
        print(f"Getting events with category filter: {category}")
        
        global last_polymarket_sync
        now = datetime.utcnow()
        if (now - last_polymarket_sync).total_seconds() >= POLYMARKET_SYNC_INTERVAL_SECONDS:
            print("Triggering automatic sync...")
            sync_polymarket_events(db)
            last_polymarket_sync = datetime.utcnow()
        
        query = db.query(Event).filter(
            Event.is_active == True,
            Event.end_time > datetime.utcnow()
        )

        if category and category != 'all':
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–±—ã—Ç–∏—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            query = db.query(Event).filter(
                Event.is_active == True,
                Event.end_time > datetime.utcnow(),
                Event.category == category
            )
            events = query.order_by(Event.total_pool.desc()).limit(50).all()
            print(f"   Found {len(events)} events for category: {category}")
        else:
            query = db.query(Event).filter(
                Event.is_active == True,
                Event.end_time > datetime.utcnow()
            )
            events = query.order_by(Event.total_pool.desc()).limit(50).all()
            print(f"   Found {len(events)} events in database")
        
        result = []
        for event in events:
            print(f"   Processing event: {event.title} (ID: {event.id})")
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ü–∏–∏
            options = db.query(EventOption).filter(
                EventOption.event_id == event.id
            ).all()
            
            print(f"      - Found {len(options)} options in database")
            
            # –ü–∞—Ä—Å–∏–º –æ–ø—Ü–∏–∏ –∏–∑ JSON –µ—Å–ª–∏ –Ω–µ—Ç –≤ EventOption
            if not options and event.options:
                try:
                    options_list = json.loads(event.options)
                    print(f"      - Creating {len(options_list)} options from JSON")
                    for idx, opt_text in enumerate(options_list):
                        opt = EventOption(
                            event_id=event.id,
                            option_index=idx,
                            option_text=opt_text,
                            total_stake=0.0,
                            market_stake=0.0
                        )
                        db.add(opt)
                    db.commit()
                    options = db.query(EventOption).filter(
                        EventOption.event_id == event.id
                    ).all()
                    print(f"      - Created {len(options)} options successfully")
                except Exception as e:
                    print(f"      - Error creating options from JSON: {e}")
                    pass
            
            # –í—ã—á–∏—Å–ª—è–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è
            time_left = int((event.end_time - datetime.utcnow()).total_seconds())
            total_stakes = sum(
                (opt.total_stake or 0.0) + (opt.market_stake or 0.0)
                for opt in options
            ) or 1
            
            event_data = {
                "id": event.id,
                "polymarket_id": event.polymarket_id,
                "title": event.title,
                "description": event.description,
                "category": event.category or "other",
                "image_url": event.image_url,
                "end_time": event.end_time.isoformat(),
                "time_left": max(0, time_left),
                "total_pool": event.total_pool,
                "options": [
                    {
                        "index": opt.option_index,
                        "text": opt.option_text,
                        "total_points": (opt.total_stake or 0.0) + (opt.market_stake or 0.0),
                        "probability": round(((opt.total_stake or 0.0) + (opt.market_stake or 0.0)) / total_stakes * 100, 1)
                    }
                    for opt in options
                ]
            }
            
            result.append(event_data)
            print(f"      Added event to result: {len(event_data['options'])} options")
        
        print(f"Returning {len(result)} events to frontend")
        return {"events": result}
    except Exception as e:
        print(f"Error loading events: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/events/{event_id}")
async def get_event(event_id: int, db: Session = Depends(get_db)):
    """Get single event by ID"""
    try:
        event = db.query(Event).filter(Event.id == event_id).first()
        if not event:
            raise HTTPException(status_code=404, detail="Event not found")

        options = db.query(EventOption).filter(EventOption.event_id == event_id).all()
        time_left = int((event.end_time - datetime.utcnow()).total_seconds())
        total_stakes = sum(
            (opt.total_stake or 0.0) + (opt.market_stake or 0.0)
            for opt in options
        ) or 1

        return {
            "id": event.id,
            "title": event.title,
            "description": event.description,
            "category": event.category or "other",
            "image_url": event.image_url,
            "end_time": event.end_time.isoformat(),
            "time_left": max(0, time_left),
            "total_pool": event.total_pool,
            "options": [
                {
                    "index": opt.option_index,
                    "text": opt.option_text,
                    "total_points": (opt.total_stake or 0.0) + (opt.market_stake or 0.0),
                    "probability": round(((opt.total_stake or 0.0) + (opt.market_stake or 0.0)) / total_stakes * 100, 1)
                }
                for opt in options
            ]
        }
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error loading event: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/events/{event_id}/price-history")
async def get_price_history(event_id: int, db: Session = Depends(get_db)):
    """Get price history for event chart"""
    try:
        # Get last 48 hours of price history
        history = db.query(PriceHistory).filter(
            PriceHistory.event_id == event_id
        ).order_by(PriceHistory.timestamp.desc()).limit(100).all()

        return [
            {
                "event_id": h.event_id,
                "option_index": h.option_index,
                "price": h.price,
                "volume": h.volume,
                "timestamp": h.timestamp.isoformat()
            }
            for h in history
        ]
    except Exception as e:
        print(f"Error loading price history: {e}")
        return []

@app.get("/proxy/image")
async def proxy_image(url: str):
    """–ü—Ä–æ–∫—Å–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—Ö–æ–¥–∞ CORS"""
    try:
        if not url:
            raise HTTPException(status_code=400, detail="URL required")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ URL —Å Polymarket
        if not url.startswith('https://gamma-api.polymarket.com'):
            # –†–∞–∑—Ä–µ—à–∞–µ–º —Ç–æ–ª—å–∫–æ Polymarket images
            if not any(domain in url for domain in ['polymarket.com', 'polygon.com']):
                raise HTTPException(status_code=400, detail="Only Polymarket images allowed")
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Accept": "image/webp,image/apng,image/*,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
        }
        
        response = requests.get(url, headers=headers, timeout=30)
        
        if response.status_code != 200:
            raise HTTPException(status_code=404, detail="Image not found")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º content-type
        content_type = response.headers.get('content-type', 'image/jpeg')
        if not content_type.startswith('image/'):
            content_type = 'image/jpeg'
        
        from fastapi.responses import Response
        return Response(
            content=response.content,
            media_type=content_type,
            headers={
                "Cache-Control": "public, max-age=86400",  # –ö—ç—à –Ω–∞ 24 —á–∞—Å–∞
                "Access-Control-Allow-Origin": "*"
            }
        )
    except HTTPException:
        raise
    except Exception as e:
        print(f"Proxy image error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/user/{telegram_id}")
async def get_user(telegram_id: int, db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
    user = db.query(User).filter(User.telegram_id == telegram_id).first()
    
    if not user:
        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ –æ—á–∫–∞–º–∏
        user = User(
            telegram_id=telegram_id,
            balance_usdt=1000.0  # –°—Ç–∞—Ä—Ç–æ–≤—ã–µ –æ—á–∫–∏
        )
        db.add(user)
        db.commit()
        db.refresh(user)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    active_predictions = db.query(UserPrediction).filter(
        UserPrediction.user_id == user.id,
        UserPrediction.is_winner == None
    ).count()
    
    return {
        "telegram_id": user.telegram_id,
        "username": user.username,
        "points": user.balance_usdt,
        "stats": {
            "active_predictions": active_predictions,
            "total_won": 0,
            "total_lost": 0
        }
    }

@app.post("/predict")
async def make_prediction(request: PredictionRequest, db: Session = Depends(get_db)):
    """–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user = db.query(User).filter(User.telegram_id == request.telegram_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å
        if user.balance_usdt < request.points:
            raise HTTPException(status_code=400, detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ä–µ–¥—Å—Ç–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–±—ã—Ç–∏–µ
        event = db.query(Event).filter(Event.id == request.event_id).first()
        if not event or not event.is_active:
            raise HTTPException(status_code=404, detail="–°–æ–±—ã—Ç–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        if event.end_time <= datetime.utcnow():
            raise HTTPException(status_code=400, detail="–°–æ–±—ã—Ç–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        # –°–ø–∏—Å—ã–≤–∞–µ–º —Å—Ä–µ–¥—Å—Ç–≤–∞
        user.balance_usdt -= request.points
        
        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–≥–Ω–æ–∑
        prediction = UserPrediction(
            user_id=user.id,
            event_id=event.id,
            option_index=request.option_index,
            amount=request.points,
            asset="USDT"
        )
        db.add(prediction)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–ø—Ü–∏–∏
        option = db.query(EventOption).filter(
            EventOption.event_id == event.id,
            EventOption.option_index == request.option_index
        ).first()
        
        if option:
            option.total_stake += request.points
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–π –ø—É–ª
        event.total_pool += request.points
        
        db.commit()
        
        return {
            "success": True,
            "message": "–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–∏–Ω—è—Ç",
            "new_balance": user.balance_usdt
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        print(f"Error making prediction: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/admin/sync-polymarket")
async def manual_sync(db: Session = Depends(get_db)):
    """–†—É—á–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π –∏–∑ Polymarket"""
    try:
        count = sync_polymarket_events(db)
        return {
            "success": True,
            "message": f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–±—ã—Ç–∏–π: {count}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/admin/force-sync")
async def force_sync_polymarket(
    admin_telegram_id: int = Query(None),
    db: Session = Depends(get_db)
):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å Polymarket"""
    try:
        count = sync_polymarket_events(db)
        global last_polymarket_sync
        last_polymarket_sync = datetime.utcnow()
        return {
            "success": True,
            "synced_events": count,
            "message": f"Successfully synced {count} events from Polymarket"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/admin/debug-sync")
async def debug_sync(db: Session = Depends(get_db)):
    """Debug sync endpoint with detailed output"""
    import io
    import sys
    
    # Capture stdout
    old_stdout = sys.stdout
    sys.stdout = buffer = io.StringIO()
    
    try:
        # Call fetch directly
        events = fetch_polymarket_events(limit=5)
        
        # Get captured output
        sys.stdout = old_stdout
        logs = buffer.getvalue()
        
        return {
            "success": True,
            "events_count": len(events),
            "events": events[:2] if events else [],
            "logs": logs[:2000] if logs else "No logs captured"
        }
    except Exception as e:
        sys.stdout = old_stdout
        logs = buffer.getvalue()
        return {
            "success": False,
            "error": str(e),
            "logs": logs[:2000] if logs else "No logs captured"
        }

# ==================== ADMIN ENDPOINTS ====================

@app.get("/admin/check/{telegram_id}")
async def check_admin(telegram_id: int):
    """Check if user is admin"""
    return {"is_admin": telegram_id == ADMIN_TELEGRAM_ID}

@app.get("/admin/stats")
async def get_admin_stats(db: Session = Depends(get_db)):
    """Get admin statistics"""
    total_users = db.query(User).count()
    total_events = db.query(Event).filter(Event.is_moderated == True).count()
    pending_events = db.query(Event).filter(Event.is_moderated == False).count()
    total_volume = db.query(Event).filter(
        Event.is_moderated == True
    ).with_entities(func.sum(Event.total_pool)).scalar() or 0.0
    total_transactions = db.query(Transaction).count()

    return {
        "total_users": total_users,
        "total_events": total_events,
        "pending_events": pending_events,
        "total_volume": round(total_volume, 2),
        "total_transactions": total_transactions
    }

@app.get("/admin/pending-events")
async def get_pending_events(db: Session = Depends(get_db)):
    """Get events pending moderation"""
    events = db.query(Event).filter(Event.is_moderated == False).all()
    return {
        "events": [
            {
                "id": e.id,
                "title": e.title,
                "category": e.category,
                "created_by": e.creator_id,
                "end_time": e.end_time.isoformat()
            }
            for e in events
        ]
    }

@app.post("/admin/event/action")
async def moderate_event(
    event_id: int,
    action: str,  # "approve" or "reject"
    telegram_id: int,
    db: Session = Depends(get_db)
):
    """Approve or reject event"""
    if telegram_id != ADMIN_TELEGRAM_ID:
        raise HTTPException(status_code=403, detail="Not authorized")

    event = db.query(Event).filter(Event.id == event_id).first()
    if not event:
        raise HTTPException(status_code=404, detail="Event not found")

    if action == "approve":
        event.is_moderated = True
        db.commit()
        return {"success": True, "message": "Event approved"}
    elif action == "reject":
        db.delete(event)
        db.commit()
        return {"success": True, "message": "Event rejected"}
    else:
        raise HTTPException(status_code=400, detail="Invalid action")

@app.get("/admin/user/{telegram_id}")
async def get_user_admin(telegram_id: int, db: Session = Depends(get_db)):
    """Get user info for admin"""
    user = db.query(User).filter(User.telegram_id == telegram_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")

    transactions = db.query(Transaction).filter(
        Transaction.user_id == user.id
    ).order_by(Transaction.created_at.desc()).limit(20).all()

    return {
        "telegram_id": user.telegram_id,
        "username": user.username,
        "balance_usdt": user.balance_usdt,
        "balance_ton": user.balance_ton,
        "is_blocked": user.is_blocked,
        "created_at": user.created_at.isoformat(),
        "transactions": [
            {
                "id": t.id,
                "type": t.type,
                "amount": t.amount,
                "status": t.status,
                "created_at": t.created_at.isoformat()
            }
            for t in transactions
        ]
    }

@app.post("/admin/user/balance")
async def update_user_balance(
    telegram_id: int,
    amount: float,
    action: str,  # "add" or "set"
    admin_telegram_id: int,
    db: Session = Depends(get_db)
):
    """Update user balance (admin only)"""
    if admin_telegram_id != ADMIN_TELEGRAM_ID:
        raise HTTPException(status_code=403, detail="Not authorized")

    user = db.query(User).filter(User.telegram_id == telegram_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")

    if action == "add":
        user.balance_usdt += amount
    elif action == "set":
        user.balance_usdt = amount

    db.commit()
    return {"success": True, "new_balance": user.balance_usdt}

@app.post("/events/create")
async def create_event(request: CreateEventRequest, db: Session = Depends(get_db)):
    """Create a new event (requires moderation)"""
    try:
        # Check if user has enough balance for creation (min $10)
        user = db.query(User).filter(User.telegram_id == request.telegram_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")

        if user.balance_usdt < 10:
            raise HTTPException(status_code=400, detail="Insufficient balance. Minimum $10 required to create event")

        # Parse end time
        try:
            end_time = datetime.fromisoformat(request.end_time.replace('Z', '+00:00'))
        except:
            end_time = datetime.utcnow() + timedelta(days=7)

        # Create event (not moderated by default)
        new_event = Event(
            polymarket_id=f"user_{request.telegram_id}_{int(datetime.utcnow().timestamp())}",
            title=request.title[:500],
            description=request.description[:1000] if request.description else None,
            category=request.category or 'other',
            image_url=request.image_url or '',
            options=json.dumps(request.options),
            end_time=end_time,
            is_active=True,
            is_moderated=False,  # Requires moderation
            is_resolved=False,
            total_pool=0.0,
            creator_id=user.id
        )
        db.add(new_event)
        db.flush()

        # Create options
        for idx, option_text in enumerate(request.options):
            new_option = EventOption(
                event_id=new_event.id,
                option_index=idx,
                option_text=option_text[:255],
                total_stake=0.0,
                market_stake=0.0
            )
            db.add(new_option)

        db.commit()
        db.refresh(new_event)

        return {
            "success": True,
            "event_id": new_event.id,
            "message": "Event created and sent for moderation"
        }
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error creating event: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Health check
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "sync": {
            "last_sync": sync_stats["last_sync"].isoformat() if sync_stats["last_sync"] else None,
            "total_synced": sync_stats["total_synced"],
            "last_error": sync_stats["last_error"],
            "next_sync_in": POLYMARKET_SYNC_INTERVAL_SECONDS
        }
    }


if os.path.isdir(FRONTEND_DIR):
    app.mount("/frontend", StaticFiles(directory=FRONTEND_DIR), name="frontend")


@app.get("/{file_path:path}", include_in_schema=False)
async def serve_frontend_assets(file_path: str):
    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º API-–º–∞—Ä—à—Ä—É—Ç—ã –∏ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
    reserved_prefixes = ("api/", "docs", "redoc", "openapi.json")
    if file_path.startswith(reserved_prefixes):
        raise HTTPException(status_code=404, detail="Not found")

    candidate = os.path.join(FRONTEND_DIR, file_path)
    if os.path.isfile(candidate):
        return FileResponse(candidate)

    index_path = os.path.join(FRONTEND_DIR, "index.html")
    if os.path.exists(index_path):
        return FileResponse(index_path)
    raise HTTPException(status_code=404, detail="Frontend not found")

class handler(BaseHTTPRequestHandler):
    def _run_app(self):
        body_length = int(self.headers.get("content-length", 0) or 0)
        body = self.rfile.read(body_length) if body_length > 0 else b""

        url = urlsplit(self.path)
        headers = [
            (key.lower().encode("latin-1"), value.encode("latin-1"))
            for key, value in self.headers.items()
        ]

        scope = {
            "type": "http",
            "asgi": {"version": "3.0"},
            "http_version": self.request_version.replace("HTTP/", ""),
            "method": self.command,
            "scheme": "https",
            "path": url.path,
            "raw_path": url.path.encode("utf-8"),
            "query_string": url.query.encode("utf-8"),
            "headers": headers,
            "client": self.client_address,
            "server": (self.server.server_address[0], self.server.server_address[1]),
        }

        response = {"status": 500, "headers": [], "body": b""}

        async def receive():
            return {"type": "http.request", "body": body, "more_body": False}

        async def send(message):
            if message["type"] == "http.response.start":
                response["status"] = message["status"]
                response["headers"] = message.get("headers", [])
            elif message["type"] == "http.response.body":
                response["body"] += message.get("body", b"")

        async def app_runner():
            await app(scope, receive, send)

        asyncio.run(app_runner())

        self.send_response(response["status"])
        for key, value in response["headers"]:
            self.send_header(key.decode("latin-1"), value.decode("latin-1"))
        self.end_headers()
        self.wfile.write(response["body"])

    def do_GET(self):
        self._run_app()

    def do_POST(self):
        self._run_app()

    def do_PUT(self):
        self._run_app()

    def do_PATCH(self):
        self._run_app()

    def do_DELETE(self):
        self._run_app()

    def do_OPTIONS(self):
        self._run_app()
