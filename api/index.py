from fastapi import FastAPI, HTTPException, Depends, Query
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from pydantic import BaseModel
from datetime import datetime, timedelta
import json
import requests
from typing import List, Optional
import os
import asyncio
import logging
from http.server import BaseHTTPRequestHandler
from urllib.parse import urlsplit
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from apscheduler.schedulers.asyncio import AsyncIOScheduler

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π
try:
    from .models import (
        get_db, User, Event, EventOption, UserPrediction, 
        Transaction, TransactionType, TransactionStatus
    )
except ImportError:
    from models import (
        get_db, User, Event, EventOption, UserPrediction, 
        Transaction, TransactionType, TransactionStatus
    )

app = FastAPI(title="EventPredict API")

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
FRONTEND_DIR = os.path.join(BASE_DIR, "frontend")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# CORS –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Vercel routes keep the "/api" prefix; strip it so FastAPI routes match.
@app.middleware("http")
async def strip_api_prefix(request, call_next):
    path = request.scope.get("path", "")
    if path == "/api":
        request.scope["path"] = "/"
    elif path.startswith("/api/"):
        request.scope["path"] = path[4:] or "/"
    return await call_next(request)

# ==================== POLYMARKET API INTEGRATION ====================

POLYMARKET_API_URL = "https://gamma-api.polymarket.com"
# –ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: 2 —á–∞—Å–∞ (7200 —Å–µ–∫—É–Ω–¥) –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –∫—Ä–µ–¥–∏—Ç–æ–≤ Railway
POLYMARKET_SYNC_INTERVAL_SECONDS = int(os.getenv("POLYMARKET_SYNC_INTERVAL", "7200"))
last_polymarket_sync = datetime.min
sync_stats = {"total_synced": 0, "last_sync": None, "last_error": None}
POLYMARKET_VERBOSE_LOGS = os.getenv("POLYMARKET_VERBOSE_LOGS", "0") == "1"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
scheduler = AsyncIOScheduler()

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
CATEGORY_KEYWORDS = {
    'politics': ['trump', 'biden', 'election', 'president', 'congress', 'senate', 'vote', 'democrat', 'republican', 'political', 'government', 'minister', 'parliament', 'putin', 'zelensky', 'ukraine', 'russia', 'china', 'nato'],
    'sports': ['nba', 'nfl', 'mlb', 'soccer', 'football', 'basketball', 'baseball', 'tennis', 'golf', 'ufc', 'boxing', 'f1', 'formula', 'championship', 'world cup', 'super bowl', 'olympics', 'game', 'match', 'team', 'player'],
    'crypto': ['bitcoin', 'btc', 'ethereum', 'eth', 'crypto', 'blockchain', 'defi', 'nft', 'token', 'coin', 'binance', 'coinbase', 'solana', 'dogecoin', 'altcoin', 'mining'],
    'pop_culture': ['movie', 'film', 'oscar', 'grammy', 'emmy', 'celebrity', 'music', 'album', 'artist', 'actor', 'actress', 'tv show', 'netflix', 'disney', 'marvel', 'star wars', 'taylor swift', 'beyonce', 'kanye'],
    'business': ['stock', 'market', 'company', 'ceo', 'ipo', 'merger', 'earnings', 'revenue', 'tesla', 'apple', 'google', 'amazon', 'microsoft', 'nvidia', 'ai', 'layoff', 'startup', 'fed', 'interest rate', 'inflation'],
    'science': ['nasa', 'spacex', 'rocket', 'mars', 'moon', 'climate', 'vaccine', 'fda', 'research', 'discovery', 'scientist', 'study', 'experiment', 'technology', 'ai model', 'gpt', 'openai']
}

def detect_category(title: str, description: str = '') -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å–æ–±—ã—Ç–∏—è –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É –∏ –æ–ø–∏—Å–∞–Ω–∏—é"""
    text = (title + ' ' + (description or '')).lower()

    category_scores = {}
    for category, keywords in CATEGORY_KEYWORDS.items():
        score = sum(1 for keyword in keywords if keyword in text)
        if score > 0:
            category_scores[category] = score

    if category_scores:
        return max(category_scores, key=category_scores.get)
    return 'other'

def fetch_polymarket_events(limit: int = 50, category: str = None):
    """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –∏–∑ Polymarket API"""
    try:
        print(f"=== fetch_polymarket_events START ===")
        print(f"Limit: {limit}, Category: {category}")
        
        # –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ /markets —á–∞—â–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è (–≤–∫–ª—é—á–∞—è –∏—Å—Ö–æ–¥—ã)
        primary_url = "https://gamma-api.polymarket.com/markets"
        secondary_url = "https://gamma-api.polymarket.com/events"

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ (–≤–∞–∂–Ω–æ: –ù–ï –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º brotli 'br', —Ç.–∫. requests –±–µ–∑ –¥–æ–ø. –ø–∞–∫–µ—Ç–æ–≤ –º–æ–∂–µ—Ç –Ω–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å)
        headers = {
            "Accept": "application/json",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Accept-Language": "en-US,en;q=0.9",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
        }

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–¥–ª—è /markets –∏ /events)
        params = {
            "order": "id",
            "ascending": "false",
            "closed": "false",
            "active": "true",
            "limit": limit,
        }

        def _do_get(url: str):
            if POLYMARKET_VERBOSE_LOGS:
                print(f"Fetching from Polymarket: {url}")
                print(f"Params: {params}")
            resp = requests.get(url, params=params, headers=headers, timeout=30)
            print(f"Response: status={resp.status_code}, content-length={len(resp.content)}")
            return resp

        response = _do_get(primary_url)
        
        if POLYMARKET_VERBOSE_LOGS:
            print(f"Response status: {response.status_code}")
            print(f"Content-Type: {response.headers.get('content-type', 'unknown')}")
        
        if response.status_code != 200:
            print(f"HTTP error: {response.status_code}")
            print(f"Response: {response.text[:500]}")
            # fallback to /events
            response = _do_get(secondary_url)

        if response.status_code != 200:
            print(f"HTTP error: {response.status_code}")
            print(f"Response: {response.text[:500]}")
            return []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Content-Type
        content_type = response.headers.get('content-type', '').lower()
        if 'application/json' not in content_type:
            print(f"Wrong content-type: {content_type}")
            print(f"Response preview: {response.text[:200]}")
            return []

        if POLYMARKET_VERBOSE_LOGS:
            print(f"Response preview (first 1000 chars): {response.text[:1000]}")
        
        try:
            events_data = response.json()
        except ValueError as e:
            print(f"JSON parsing error: {e}")
            print(f"Response preview: {response.text[:200]}")
            return []

        # API –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫, –ª–∏–±–æ –æ–±—ä–µ–∫—Ç –≤–∏–¥–∞ {"events": [...]}/{"markets": [...]}
        events_list = None
        if isinstance(events_data, list):
            events_list = events_data
        elif isinstance(events_data, dict):
            if isinstance(events_data.get("events"), list):
                events_list = events_data.get("events")
            elif isinstance(events_data.get("markets"), list):
                events_list = events_data.get("markets")
            elif isinstance(events_data.get("data"), list):
                events_list = events_data.get("data")
            elif isinstance(events_data.get("results"), list):
                events_list = events_data.get("results")

        if events_list is None:
            print(f"Unexpected Polymarket response shape: {type(events_data)}")
            if POLYMARKET_VERBOSE_LOGS:
                print(f"Response preview: {str(events_data)[:1000]}")
            return []

        print(f"Received {len(events_list)} events from Polymarket")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä—ã–Ω–∫–∏/—Å–æ–±—ã—Ç–∏—è
        events = []
        for idx, event in enumerate(events_list):
            if POLYMARKET_VERBOSE_LOGS:
                print(f"Processing event #{idx}: {str(event)[:200]}...")
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞
            question = event.get('question') or event.get('title') or event.get('description')
            if not question:
                print("   No question/title/description found")
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥—ã/–æ–ø—Ü–∏–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
            tokens = event.get("tokens")
            outcomes = event.get("outcomes")
            outcome_prices = event.get("outcomePrices") or event.get("outcome_prices")

            options = []
            volumes = []

            # –ü–∞—Ä—Å–∏–º outcomes –µ—Å–ª–∏ —ç—Ç–æ JSON —Å—Ç—Ä–æ–∫–∞
            if isinstance(outcomes, str):
                try:
                    outcomes = json.loads(outcomes)
                except Exception:
                    pass

            # 1) tokens (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç)
            if isinstance(tokens, list) and tokens:
                for token in tokens:
                    outcome = token.get("outcome", "")
                    if not outcome:
                        continue
                    price = float(token.get("price", 0.5) or 0.5)
                    options.append(outcome)
                    volumes.append(price * 1000)

            # 2) outcomes + outcomePrices (—á–∞—Å—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç /markets)
            elif isinstance(outcomes, list) and outcomes:
                options = [str(o) for o in outcomes]
                if isinstance(outcome_prices, list) and len(outcome_prices) == len(options):
                    for p in outcome_prices:
                        try:
                            volumes.append(float(p) * 1000)
                        except Exception:
                            volumes.append(500.0)
                else:
                    volumes = [500.0 for _ in options]

            if not options:
                # –ù–µ—á–µ–≥–æ —Å–∏–Ω–∫–∞—Ç—å
                continue
            
            if POLYMARKET_VERBOSE_LOGS:
                print(f"   Found question: {question}")
                print(f"   Found {len(tokens)} tokens")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–±—ã—Ç–∏—è
            title = question
            description = event.get('description', '')
            detected_category = detect_category(title, description)

            if category and category != 'all' and detected_category != category:
                print(f"   Skipping - category {detected_category} != {category}")
                continue

            if POLYMARKET_VERBOSE_LOGS:
                print(f"   Options: {options}")
            
            # –ü–æ–ª—É—á–∞–µ–º ID —Å–æ–±—ã—Ç–∏—è
            event_id = event.get('conditionId') or event.get('id') or str(idx)
            
            event_data = {
                'polymarket_id': event_id,
                'title': title,
                'description': description,
                'category': detected_category,
                'image_url': event.get('image', ''),
                'end_time': event.get('endDate', '') or event.get('end_date', ''),
                'options': options,
                'volumes': volumes
            }
            
            events.append(event_data)
            if POLYMARKET_VERBOSE_LOGS:
                print(f"   Created event data: {title}")
        
        print(f"Processed {len(events)} valid events")
        print(f"=== fetch_polymarket_events END ===")
        return events

    except requests.exceptions.RequestException as e:
        print(f"Network error: {e}")
        print(f"=== fetch_polymarket_events ERROR ===")
        return []
    except Exception as e:
        print(f"Error fetching Polymarket events: {e}")
        import traceback
        traceback.print_exc()
        print(f"=== fetch_polymarket_events ERROR ===")
        return []

def parse_polymarket_end_time(end_time: str) -> datetime:
    if not end_time:
        return datetime.utcnow() + timedelta(days=7)
    try:
        # Parse with timezone and convert to naive UTC
        dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
        return dt.replace(tzinfo=None)  # Convert to naive UTC
    except Exception as e:
        print(f"Error parsing end time: {e}")
        return datetime.utcnow() + timedelta(days=7)

def update_event_total_pool(db: Session, event: Event) -> None:
    options = db.query(EventOption).filter(EventOption.event_id == event.id).all()
    event.total_pool = sum(
        (opt.total_stake or 0.0) + (opt.market_stake or 0.0)
        for opt in options
    )

def upsert_polymarket_event(db: Session, pm_event: dict) -> bool:
    print(f"Upserting event: {pm_event.get('title', 'No title')}")
    
    end_time = parse_polymarket_end_time(pm_event.get('end_time'))
    is_active = end_time > datetime.utcnow()
    options = pm_event.get('options', [])
    volumes = pm_event.get('volumes', [])
    
    print(f"   - Parsed end time: {end_time}")
    print(f"   - Is active: {is_active}")
    print(f"   - Options count: {len(options)}")
    print(f"   - Volumes: {volumes}")

    polymarket_id = pm_event.get('polymarket_id', '')
    if not polymarket_id:
        print("   No polymarket_id - skipping")
        return False

    existing = db.query(Event).filter(
        Event.polymarket_id == polymarket_id
    ).first()

    if existing:
        print(f"   Updating existing event (ID: {existing.id})")
        existing.title = pm_event['title'][:500]
        existing.description = pm_event['description'][:1000] if pm_event['description'] else None
        existing.category = pm_event.get('category', existing.category)
        existing.image_url = pm_event.get('image_url', '')
        existing.end_time = end_time
        existing.is_active = is_active
        existing.options = json.dumps(options)

        existing_options = {
            opt.option_index: opt
            for opt in db.query(EventOption).filter(EventOption.event_id == existing.id).all()
        }

        for idx, (option_text, volume) in enumerate(zip(options, volumes)):
            option = existing_options.get(idx)
            if option:
                option.option_text = option_text
                option.market_stake = volume
                print(f"   Updated option {idx}: {option_text}")
            else:
                new_option = EventOption(
                    event_id=existing.id,
                    option_index=idx,
                    option_text=option_text,
                    total_stake=0.0,
                    market_stake=volume
                )
                db.add(new_option)
                print(f"   Added option {idx}: {option_text}")

        for idx, option in existing_options.items():
            if idx >= len(options):
                db.delete(option)
                print(f"   Deleted option {idx}")

        update_event_total_pool(db, existing)
        print("   Event updated successfully")
        return False

    print("   Creating new event")
    new_event = Event(
        polymarket_id=polymarket_id,
        title=pm_event['title'][:500],
        description=pm_event['description'][:1000] if pm_event['description'] else None,
        category=pm_event.get('category', 'other'),
        image_url=pm_event.get('image_url', ''),
        options=json.dumps(options),
        end_time=end_time,
        is_active=is_active,
        is_moderated=True,
        total_pool=sum(volumes)
    )
    db.add(new_event)
    db.flush()
    print(f"   Created event with ID: {new_event.id}")

    for idx, (option_text, volume) in enumerate(zip(options, volumes)):
        new_option = EventOption(
            event_id=new_event.id,
            option_index=idx,
            option_text=option_text,
            total_stake=0.0,
            market_stake=volume
        )
        db.add(new_option)
        print(f"   Added option {idx}: {option_text}")

    print(f"   New event created successfully")
    return True


def sync_polymarket_events(db: Session = None):
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Å–æ–±—ã—Ç–∏—è –∏–∑ Polymarket –≤ –ë–î"""
    try:
        logger.info("üîÑ Starting Polymarket sync...")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é –ë–î –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞
        if db is None:
            db = next(get_db())
        
        polymarket_events = fetch_polymarket_events(limit=100)
        synced_count = 0
        added_count = 0
        updated_count = 0

        for pm_event in polymarket_events:
            created = upsert_polymarket_event(db, pm_event)
            if created:
                added_count += 1
            else:
                updated_count += 1
            synced_count += 1
            logger.info(f"  {'‚úÖ Added' if created else 'üîÑ Updated'}: {pm_event['title'][:50]}...")

        db.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        sync_stats["total_synced"] = synced_count
        sync_stats["last_sync"] = datetime.utcnow()
        sync_stats["last_error"] = None
        
        logger.info(f"‚úÖ Sync completed: {synced_count} events ({added_count} new, {updated_count} updated)")
        return synced_count
    except Exception as e:
        logger.error(f"‚ùå Error syncing events: {e}")
        sync_stats["last_error"] = str(e)
        return 0


def scheduled_sync():
    """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
    try:
        sync_polymarket_events()
    except Exception as e:
        logger.error(f"Scheduled sync error: {e}")

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    logger.info("üöÄ Starting EventPredict API...")

    # –û—Ç–∫–ª—é—á–∞–µ–º scheduler –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
    if not os.getenv("DISABLE_SCHEDULER"):
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
        scheduler.add_job(
            scheduled_sync,
            'interval',
            seconds=POLYMARKET_SYNC_INTERVAL_SECONDS,
            id='polymarket_sync',
            replace_existing=True
        )
        scheduler.start()
        logger.info(f"‚è∞ Scheduler started (interval: {POLYMARKET_SYNC_INTERVAL_SECONDS}s)")

        # –ü–µ—Ä–≤–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        try:
            db = next(get_db())
            sync_polymarket_events(db)
        except Exception as e:
            logger.error(f"Initial sync error: {e}")
    else:
        logger.info("üß™ Test mode: scheduler disabled")


@app.on_event("shutdown")
async def shutdown_event():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã"""
    logger.info("üõë Shutting down EventPredict API...")
    if not os.getenv("DISABLE_SCHEDULER"):
        scheduler.shutdown(wait=False)

# ==================== PYDANTIC MODELS ====================

class PredictionRequest(BaseModel):
    telegram_id: int
    event_id: int
    option_index: int
    points: float

class UserResponse(BaseModel):
    telegram_id: int
    username: Optional[str]
    points: float
    stats: dict


# ==================== API ENDPOINTS ====================
@app.get("/", include_in_schema=False)
async def root():
    index_path = os.path.join(FRONTEND_DIR, "index.html")
    if os.path.exists(index_path):
        return FileResponse(index_path)
    return {"status": "ok", "message": "EventPredict API"}

@app.get("/categories")
async def get_categories():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
    return {
        "categories": [
            {"id": "all", "name": "All", "icon": "üî•", "name_ru": "–í—Å–µ"},
            {"id": "politics", "name": "Politics", "icon": "üèõÔ∏è", "name_ru": "–ü–æ–ª–∏—Ç–∏–∫–∞"},
            {"id": "sports", "name": "Sports", "icon": "‚öΩ", "name_ru": "–°–ø–æ—Ä—Ç"},
            {"id": "crypto", "name": "Crypto", "icon": "‚Çø", "name_ru": "–ö—Ä–∏–ø—Ç–æ"},
            {"id": "pop_culture", "name": "Pop Culture", "icon": "üé¨", "name_ru": "–ü–æ–ø-–∫—É–ª—å—Ç—É—Ä–∞"},
            {"id": "business", "name": "Business", "icon": "üìà", "name_ru": "–ë–∏–∑–Ω–µ—Å"},
            {"id": "science", "name": "Science", "icon": "üî¨", "name_ru": "–ù–∞—É–∫–∞"},
            {"id": "other", "name": "Other", "icon": "üìå", "name_ru": "–î—Ä—É–≥–æ–µ"}
        ]
    }

@app.get("/events")
async def get_events(category: str = None, db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–±—ã—Ç–∏—è —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    try:
        print(f"Getting events with category filter: {category}")
        
        global last_polymarket_sync
        now = datetime.utcnow()
        if (now - last_polymarket_sync).total_seconds() >= POLYMARKET_SYNC_INTERVAL_SECONDS:
            print("Triggering automatic sync...")
            sync_polymarket_events(db)
            last_polymarket_sync = datetime.utcnow()
        
        query = db.query(Event).filter(
            Event.is_active == True,
            Event.end_time > datetime.utcnow()
        )

        if category and category != 'all':
            query = query.filter(Event.category == category)
            print(f"   Filtering by category: {category}")

        events = query.order_by(Event.total_pool.desc()).limit(50).all()
        print(f"   Found {len(events)} events in database")
        
        result = []
        for event in events:
            print(f"   Processing event: {event.title} (ID: {event.id})")
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ü–∏–∏
            options = db.query(EventOption).filter(
                EventOption.event_id == event.id
            ).all()
            
            print(f"      - Found {len(options)} options in database")
            
            # –ü–∞—Ä—Å–∏–º –æ–ø—Ü–∏–∏ –∏–∑ JSON –µ—Å–ª–∏ –Ω–µ—Ç –≤ EventOption
            if not options and event.options:
                try:
                    options_list = json.loads(event.options)
                    print(f"      - Creating {len(options_list)} options from JSON")
                    for idx, opt_text in enumerate(options_list):
                        opt = EventOption(
                            event_id=event.id,
                            option_index=idx,
                            option_text=opt_text,
                            total_stake=0.0,
                            market_stake=0.0
                        )
                        db.add(opt)
                    db.commit()
                    options = db.query(EventOption).filter(
                        EventOption.event_id == event.id
                    ).all()
                    print(f"      - Created {len(options)} options successfully")
                except Exception as e:
                    print(f"      - Error creating options from JSON: {e}")
                    pass
            
            # –í—ã—á–∏—Å–ª—è–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è
            time_left = int((event.end_time - datetime.utcnow()).total_seconds())
            total_stakes = sum(
                (opt.total_stake or 0.0) + (opt.market_stake or 0.0)
                for opt in options
            ) or 1
            
            event_data = {
                "id": event.id,
                "title": event.title,
                "description": event.description,
                "category": event.category or "other",
                "image_url": event.image_url,
                "end_time": event.end_time.isoformat(),
                "time_left": max(0, time_left),
                "total_pool": event.total_pool,
                "options": [
                    {
                        "index": opt.option_index,
                        "text": opt.option_text,
                        "total_points": (opt.total_stake or 0.0) + (opt.market_stake or 0.0),
                        "probability": round(((opt.total_stake or 0.0) + (opt.market_stake or 0.0)) / total_stakes * 100, 1)
                    }
                    for opt in options
                ]
            }
            
            result.append(event_data)
            print(f"      Added event to result: {len(event_data['options'])} options")
        
        print(f"Returning {len(result)} events to frontend")
        return {"events": result}
    except Exception as e:
        print(f"Error loading events: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/user/{telegram_id}")
async def get_user(telegram_id: int, db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
    user = db.query(User).filter(User.telegram_id == telegram_id).first()
    
    if not user:
        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ –æ—á–∫–∞–º–∏
        user = User(
            telegram_id=telegram_id,
            balance_usdt=1000.0  # –°—Ç–∞—Ä—Ç–æ–≤—ã–µ –æ—á–∫–∏
        )
        db.add(user)
        db.commit()
        db.refresh(user)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    active_predictions = db.query(UserPrediction).filter(
        UserPrediction.user_id == user.id,
        UserPrediction.is_winner == None
    ).count()
    
    return {
        "telegram_id": user.telegram_id,
        "username": user.username,
        "points": user.balance_usdt,
        "stats": {
            "active_predictions": active_predictions,
            "total_won": 0,
            "total_lost": 0
        }
    }

@app.post("/predict")
async def make_prediction(request: PredictionRequest, db: Session = Depends(get_db)):
    """–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user = db.query(User).filter(User.telegram_id == request.telegram_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å
        if user.balance_usdt < request.points:
            raise HTTPException(status_code=400, detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ä–µ–¥—Å—Ç–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–±—ã—Ç–∏–µ
        event = db.query(Event).filter(Event.id == request.event_id).first()
        if not event or not event.is_active:
            raise HTTPException(status_code=404, detail="–°–æ–±—ã—Ç–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        if event.end_time <= datetime.utcnow():
            raise HTTPException(status_code=400, detail="–°–æ–±—ã—Ç–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        # –°–ø–∏—Å—ã–≤–∞–µ–º —Å—Ä–µ–¥—Å—Ç–≤–∞
        user.balance_usdt -= request.points
        
        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–≥–Ω–æ–∑
        prediction = UserPrediction(
            user_id=user.id,
            event_id=event.id,
            option_index=request.option_index,
            amount=request.points,
            asset="USDT"
        )
        db.add(prediction)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–ø—Ü–∏–∏
        option = db.query(EventOption).filter(
            EventOption.event_id == event.id,
            EventOption.option_index == request.option_index
        ).first()
        
        if option:
            option.total_stake += request.points
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–π –ø—É–ª
        event.total_pool += request.points
        
        db.commit()
        
        return {
            "success": True,
            "message": "–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–∏–Ω—è—Ç",
            "new_balance": user.balance_usdt
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        print(f"Error making prediction: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/admin/sync-polymarket")
async def manual_sync(db: Session = Depends(get_db)):
    """–†—É—á–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π –∏–∑ Polymarket"""
    try:
        count = sync_polymarket_events(db)
        return {
            "success": True,
            "message": f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–±—ã—Ç–∏–π: {count}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/admin/force-sync")
async def force_sync_polymarket(
    admin_telegram_id: int = Query(None),
    db: Session = Depends(get_db)
):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å Polymarket"""
    try:
        count = sync_polymarket_events(db)
        global last_polymarket_sync
        last_polymarket_sync = datetime.utcnow()
        return {
            "success": True,
            "synced_events": count,
            "message": f"Successfully synced {count} events from Polymarket"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/admin/debug-sync")
async def debug_sync(db: Session = Depends(get_db)):
    """Debug sync endpoint with detailed output"""
    import io
    import sys
    
    # Capture stdout
    old_stdout = sys.stdout
    sys.stdout = buffer = io.StringIO()
    
    try:
        # Call fetch directly
        events = fetch_polymarket_events(limit=5)
        
        # Get captured output
        sys.stdout = old_stdout
        logs = buffer.getvalue()
        
        return {
            "success": True,
            "events_count": len(events),
            "events": events[:2] if events else [],
            "logs": logs[:2000] if logs else "No logs captured"
        }
    except Exception as e:
        sys.stdout = old_stdout
        logs = buffer.getvalue()
        return {
            "success": False,
            "error": str(e),
            "logs": logs[:2000] if logs else "No logs captured"
        }

# Health check
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "sync": {
            "last_sync": sync_stats["last_sync"].isoformat() if sync_stats["last_sync"] else None,
            "total_synced": sync_stats["total_synced"],
            "last_error": sync_stats["last_error"],
            "next_sync_in": POLYMARKET_SYNC_INTERVAL_SECONDS
        }
    }


if os.path.isdir(FRONTEND_DIR):
    app.mount("/frontend", StaticFiles(directory=FRONTEND_DIR), name="frontend")


@app.get("/{file_path:path}", include_in_schema=False)
async def serve_frontend_assets(file_path: str):
    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º API-–º–∞—Ä—à—Ä—É—Ç—ã –∏ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
    reserved_prefixes = ("api/", "docs", "redoc", "openapi.json")
    if file_path.startswith(reserved_prefixes):
        raise HTTPException(status_code=404, detail="Not found")

    candidate = os.path.join(FRONTEND_DIR, file_path)
    if os.path.isfile(candidate):
        return FileResponse(candidate)

    index_path = os.path.join(FRONTEND_DIR, "index.html")
    if os.path.exists(index_path):
        return FileResponse(index_path)
    raise HTTPException(status_code=404, detail="Frontend not found")

class handler(BaseHTTPRequestHandler):
    def _run_app(self):
        body_length = int(self.headers.get("content-length", 0) or 0)
        body = self.rfile.read(body_length) if body_length > 0 else b""

        url = urlsplit(self.path)
        headers = [
            (key.lower().encode("latin-1"), value.encode("latin-1"))
            for key, value in self.headers.items()
        ]

        scope = {
            "type": "http",
            "asgi": {"version": "3.0"},
            "http_version": self.request_version.replace("HTTP/", ""),
            "method": self.command,
            "scheme": "https",
            "path": url.path,
            "raw_path": url.path.encode("utf-8"),
            "query_string": url.query.encode("utf-8"),
            "headers": headers,
            "client": self.client_address,
            "server": (self.server.server_address[0], self.server.server_address[1]),
        }

        response = {"status": 500, "headers": [], "body": b""}

        async def receive():
            return {"type": "http.request", "body": body, "more_body": False}

        async def send(message):
            if message["type"] == "http.response.start":
                response["status"] = message["status"]
                response["headers"] = message.get("headers", [])
            elif message["type"] == "http.response.body":
                response["body"] += message.get("body", b"")

        async def app_runner():
            await app(scope, receive, send)

        asyncio.run(app_runner())

        self.send_response(response["status"])
        for key, value in response["headers"]:
            self.send_header(key.decode("latin-1"), value.decode("latin-1"))
        self.end_headers()
        self.wfile.write(response["body"])

    def do_GET(self):
        self._run_app()

    def do_POST(self):
        self._run_app()

    def do_PUT(self):
        self._run_app()

    def do_PATCH(self):
        self._run_app()

    def do_DELETE(self):
        self._run_app()

    def do_OPTIONS(self):
        self._run_app()
